{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.B. Collection -- User Data -- Genius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll build on the data we have already collected from Genuis.com by extracting information on users and their artist preferences. The goal here is to build a matrix of user preferences to be applied to our recommender system. Unfortunately, this data is a little tricker to grab for a couple of reasons:\n",
    "\n",
    " - We've been using lyricsgenius as a wrapper for the Genius API, and there is no functionality with this library to access user data.\n",
    " - To my knowledge, the **user API endpoint does not contain followed artists**. This means that we need to extract user information from **artist endpoints**.\n",
    "\n",
    "To accomplish this, we'll go straight to the Genius API and search for artist profiles. The workflow is as follows:\n",
    "\n",
    " 1. Grab our list of artists from our running list of artist information. *Note: as mentioned previously, many iterations of this list have been created across Wiki, Genius, and Spotify. This is why you see duplicate lists below*\n",
    " \n",
    " \n",
    " 2. **To extract our artist information...**\n",
    "  - Find the most often occuring artist in the response we get. The first option is not *always* the one we want, but we can rely on the mode here\n",
    "  - Extract the artist name, url and profile so we can access their endpoint\n",
    "  \n",
    "  \n",
    " 3. **To extract user information...**\n",
    "  - Take the artistID and navigate to the artist profile endpoint.\n",
    "  - Here, we can iterate through every page of users that follow that artist.\n",
    "  \n",
    "A number of different approaches were tested here including the use of **Selenium** to access this information. We saw mixed results in inconsistency with this approach, but the notebook is available if there's interest in looking (with label **\"ARCHIVED\"**).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import lyricsgenius\n",
    "import selenium\n",
    "import sys\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "import statistics as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store our genius token\n",
    "genius_token = \"QH034S7zNrqva_ceDCQYvMx4K1MaSwOgABqIfQt8VjUov5mh75oTn89PzV21GwMk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab our list of rapper names for searching\n",
    "rapper_list_for_genius_df1 = pd.read_csv('combined_rapper_data_1.csv', header=None)\n",
    "rapper_list_for_genius_df2 = pd.read_csv('combined_rapper_data_2.csv', header=None)\n",
    "rapper_list_for_genius_df3 = pd.read_csv('combined_rapper_data_3.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rapper_list_for_genius_df = pd.concat([rapper_list_for_genius_df1,rapper_list_for_genius_df2,rapper_list_for_genius_df3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genius - Artist DF Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Instantiate empty list for storing our artist data. Specifically, we\n",
    "#will be looking for rapper, url, api_path, and we'll also make note of anyone we missed.\n",
    "genius_rapper_list = []\n",
    "genius_url_list = []\n",
    "genius_api_path_list = []\n",
    "missed_rappers=[]\n",
    "\n",
    "rapper_list_for_genius = list(rapper_list_for_genius_df[1].dropna())\n",
    "\n",
    "#Iterate through our list of rappers\n",
    "for rapper in rapper_list_for_genius:\n",
    "    \n",
    "    try:\n",
    "\n",
    "        #build our request to get artist data\n",
    "        base_url = 'https://api.genius.com'\n",
    "        headers = {'Authorization': 'Bearer ' + genius_token}\n",
    "        search_url = base_url + '/search'\n",
    "        data = {'q': rapper}\n",
    "        \n",
    "        #store the response that we get\n",
    "        response = requests.get(search_url, data=data, headers=headers)\n",
    "        json = response.json()['response']['hits']\n",
    "\n",
    "        #if there was anything returned from our search\n",
    "        if( len(json) > 0):\n",
    "            #Find the most frequent rapper name in the results. The first result is not reliable\n",
    "            most_freq_name = stats.mode([json[i]['result']['primary_artist']['name'] for i in range(len(json))])\n",
    "            genius_rapper_list.append(most_freq_name)\n",
    "            \n",
    "            \n",
    "            #Find the most frequent path in the results. The first result is not reliable\n",
    "            most_freq_path = stats.mode([json[i]['result']['primary_artist']['api_path'] for i in range(len(json))])\n",
    "            genius_api_path_list.append(most_freq_path)\n",
    "\n",
    "            #Find the most frequent url in the results. The first result is not reliable\n",
    "            most_freq_url = stats.mode([json[i]['result']['primary_artist']['url'] for i in range(len(json))])\n",
    "            genius_url_list.append(most_freq_url)\n",
    "        \n",
    "            print(F\"Artist Check: searched for {rapper} and found {most_freq_name}.\")\n",
    "        else:\n",
    "            \n",
    "            #if we didn't get anything, append blanks\n",
    "            print(\"we didn't get any results. Skipping artist.\")\n",
    "            genius_rapper_list.append('')\n",
    "            genius_api_path_list.append('')\n",
    "            genius_url_list.append('')\n",
    "            missed_rappers.append(rapper)\n",
    "            \n",
    "    except:\n",
    "        print(f'Skipping Artist ({rapper}) because request failed')\n",
    "        genius_rapper_list.append('')\n",
    "        genius_api_path_list.append('')\n",
    "        genius_url_list.append('')\n",
    "        missed_rappers.append(rapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build our dataframe with the lists that we created\n",
    "artist_results_df = pd.DataFrame({\n",
    "    'artist_name' : genius_rapper_list,\n",
    "    'artist_api_path' : genius_api_path_list,\n",
    "    'artist_url' : genius_url_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save it\n",
    "artist_results_df.to_csv('genius_artist_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genius -Follower DF Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Same basic process here-- well make some lists to store our user data within\n",
    "genius_artist_api_path = []\n",
    "genius_follower_names = []\n",
    "genius_follower_id = []\n",
    "genius_follower_role = []\n",
    "genius_follower_api_path =[]\n",
    "\n",
    "#iterate through our list of api_paths\n",
    "for api_path in list(artist_results_df.artist_api_path.dropna()):\n",
    "    \n",
    "    #We start out on page 1, loop 1. We'll keep going until there's no more pages of users to grab.\n",
    "    page = 1\n",
    "    loop_check = 1 \n",
    "    \n",
    "    #While there are still users\n",
    "    while(loop_check):\n",
    "        print(api_path)\n",
    "            \n",
    "        try:\n",
    "            #build our retuqest\n",
    "            base_url = 'https://genius.com/api' + api_path + '/followers?page=' + str(page)      \n",
    "            response = requests.get(base_url)\n",
    "            json = response.json()\n",
    "            \n",
    "            #If we aren't seeing many followers, we can end our loop\n",
    "            if(len(json['response']['followers']) <2):\n",
    "                loop_check=0\n",
    "            \n",
    "            #Otherwise, we need to grab follower name, id, role, and api path\n",
    "            for i in range(len(json['response']['followers'])):\n",
    "                genius_artist_api_path.append(api_path)\n",
    "                genius_follower_names.append(json['response']['followers'][i]['name'])\n",
    "                genius_follower_id.append(json['response']['followers'][i]['id'])\n",
    "                genius_follower_role.append(json['response']['followers'][i]['role_for_display'])\n",
    "                genius_follower_api_path.append(json['response']['followers'][i]['api_path'])     \n",
    "            \n",
    "            #increment our page value\n",
    "            page+=1\n",
    "                \n",
    "        except:\n",
    "            #We need to insert blanks\n",
    "            genius_artist_api_path.append('')\n",
    "            genius_follower_names.append('')\n",
    "            genius_follower_id.append('')\n",
    "            genius_follower_role.append('')\n",
    "            genius_follower_api_path.append('')\n",
    "            loop_check=0\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build our dataframe\n",
    "follower_df_test = pd.DataFrame({\n",
    "    'artist_api_path' : genius_artist_api_path,\n",
    "    'follower_name' : genius_follower_names,\n",
    "    'follower_id' : genius_follower_id,\n",
    "    'follower_role' : genius_follower_role,\n",
    "    'follower_api_path' : genius_follower_api_path\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the user is present, it's a follow. We'll use this as a proxy for ratings (unfortunately don't have this information)\n",
    "follower_df_test['follow'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to DF\n",
    "follower_df_test.to_csv('follower_genius_500k.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert artist names\n",
    "follower_df_test_w_names = pd.merge(follower_df_test,artist_results_df, how='left', on='artist_api_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['artist_api_path', 'follower_name', 'follower_id', 'follower_role',\n",
       "       'follower_api_path', 'follow', 'artist_name', 'artist_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "follower_df_test_w_names.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save this version to csv as well\n",
    "follower_df_test_w_names.to_csv('follower_genius_500k.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
