{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.C. Collection -- Audio -- Spotify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll continue with our collection workflow. To recap, we leveraged a seed list of rappers from Wikipedia to extract song data from Genius.com leveraging lyricsgenius. Now, we'll turn to **Spotify** to build on our current track level features.\n",
    "\n",
    "**Spotify** is the world's premiere streaming platform and has a robust API. There are two levels to API authorization-- the commercial version, which unlocks access to deeper metrics on user level data; the free version, which requires account authentication and unlocks access to a variety of audio features and data regarding your own account. Here, we're leveraging the latter to extract the following data:\n",
    "\n",
    " - **Pre-existing Audio Features**: *Danciness, Instrumentaliness* are one of several features that are available in Spotify's API. We'll be tapping into these\n",
    " - **Social data**: follower count, popularity are two social metrics that will help us rank artists\n",
    " - **Text data**: album, track title, data-- some basic values we'll also want to capture\n",
    " - **Audio Snippets**: We want to grab preview_urls provided by Spotify for each of our tracks. This will allow us to run custom audio analysis. *While Spotify's pre-existing audio features (danciness) are much more reliable features for classification/recommendation, our goal is to explore some of the processing steps that lead up to these pre-engineered features*\n",
    " \n",
    "The workflow for this notebook is as follows:\n",
    " 1. Instantiate connection to Spotify via **Stopipy**, a wrapper which will handle errors and streamline data collection.\n",
    " 2. Search for artists from our Genius pull, extract relevant information on artists including the **social features** mentioned above\n",
    " 3. With our list of artists, grab their full discography by iterating through album searches and corresponding track searches for each album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import lyricsgenius\n",
    "\n",
    "import sys\n",
    "import spotipy\n",
    "import spotipy.util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication and Param Setting for APIs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SPOTIFY'''\n",
    "\n",
    "scope = 'user-library-read'\n",
    "username = 'Ocurtis'\n",
    "\n",
    "#leverage stopipy's authentication method. We need to refresh this every time we pull data down.\n",
    "token = util.prompt_for_user_token(\n",
    "    username,scope,\n",
    "    client_id='INSERT ID HERE',\n",
    "    client_secret='INSERT SECRET HERE',\n",
    "    redirect_uri='http://google.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BQCXrTNl8yhMDeP7b8ycwlzpK3EMsC8Ri0mDyMuzAgL-fuHxbQGVGeR-3FW1paBYggAdndzXT8S3n-mlbYFavaC5KizSD12SxRKFwaCwIByhk1ErfcVKd8YQftgdRIjxazGolkc7AGIL14B3mgiRd_RTKayT'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Spotify Artsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the list of artists we need to pull down\n",
    "artist_list_df = pd.read_csv('missing_artists_final_push.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate for unique artist names\n",
    "spotify_query_list = list(artist_list_df['artist'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save our token and connect to Spotify via Stopipy\n",
    "sp = spotipy.Spotify(auth=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up our lists for appending as we loop through our spotify artist information\n",
    "spotify_artist_list = []\n",
    "spotify_artist_id_list = []\n",
    "spotify_artist_image_list = []\n",
    "spotify_artist_genres_list = []\n",
    "spotify_artist_popularity_list = []\n",
    "spotify_artist_follower_tot_list = []\n",
    "\n",
    "\n",
    "#Store results for our rapper in a dictionary\n",
    "for name in spotify_query_list:\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        json_spot = sp.search(q='artist:' + str(name), type='artist')\n",
    "\n",
    "\n",
    "        spotify_artist_list.append(json_spot['artists']['items'][0]['name'])\n",
    "        spotify_artist_id_list.append(json_spot['artists']['items'][0]['id'])\n",
    "\n",
    "\n",
    "        #try grabbing the first image. pass if there's a problem        \n",
    "        try:\n",
    "            spotify_artist_image_list.append(json_spot['artists']['items'][0]['url'])\n",
    "        except:\n",
    "            spotify_artist_image_list.append('')\n",
    "\n",
    "        #try grabbing the genre list. pass if there's a problem        \n",
    "        try:\n",
    "            spotify_artist_genres_list.append(\"|\".join(json_spot['artists']['items'][0]['genres']))\n",
    "        except:\n",
    "            spotify_artist_genres_list.append('')\n",
    "            \n",
    "        #try grabbing the popularity. pass if there's a problem                        \n",
    "        try:\n",
    "            spotify_artist_popularity_list.append(json_spot['artists']['items'][0]['popularity'])\n",
    "        except:\n",
    "            spotify_artist_popularity_list.append('')\n",
    "                    \n",
    "        #try grabbing the followers. pass if there's a problem    \n",
    "        try:\n",
    "            spotify_artist_follower_tot_list.append(json_spot['artists']['items'][0]['followers']['total'])\n",
    "        except:\n",
    "            spotify_artist_follower_tot_list.append('')\n",
    "\n",
    "\n",
    "    except:\n",
    "        spotify_artist_list.append('')\n",
    "        spotify_artist_id_list.append('')\n",
    "        spotify_artist_image_list.append('')\n",
    "        spotify_artist_genres_list.append('')\n",
    "        spotify_artist_popularity_list.append('')\n",
    "        spotify_artist_follower_tot_list.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Build dataframe out of our results\n",
    "spotify_artist_df = pd.DataFrame({'arist':spotify_artist_list,\n",
    "                                  'artist_id':spotify_artist_id_list,\n",
    "                                  'genres':spotify_artist_genres_list,\n",
    "                                  'image':spotify_artist_image_list,\n",
    "                                  'pop':spotify_artist_popularity_list,\n",
    "                                  'follower':spotify_artist_follower_tot_list,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop anything that has no followers -- these are junk artists\n",
    "spotify_artist_df = spotify_artist_df.loc[spotify_artist_df['follower'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to CSV\n",
    "spotify_artist_df.to_csv('spotify_artist_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read back in\n",
    "spotify_artist_df = pd.read_csv('spotify_artist_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Spotfy Album and Track Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate to our artist Id\n",
    "spotify_album_track_info_grab_list = list(spotify_album_track_info_grab_df['artist_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up track info df\n",
    "spotify_track_info_df = pd.DataFrame(columns=['album_name', 'artist_id', 'album_id', 'track_name', 'track_id',\n",
    "       'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
    "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "       'type', 'id', 'uri', 'track_href', 'analysis_url', 'duration_ms',\n",
    "       'time_signature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that will grab all related album and track information for a given artist\n",
    "def grab_album_track_info(artist_id):\n",
    "\n",
    "    #we'll keep a running tally of the full discography here\n",
    "    discog = []\n",
    "    #we'll store the album objects we get in this list\n",
    "    albums = []\n",
    "    \n",
    "    #search for albums for a given artist using Stopipy. put the return into albums\n",
    "    results = sp.artist_albums(artist_id, album_type='album')\n",
    "    albums.extend(results['items'])\n",
    "    \n",
    "    #while there are still pages of results to parse through (as signified by a 'next' key)\n",
    "    while results['next']:\n",
    "        \n",
    "        #pass Stopipy the key that will allows us to iterate through the next page\n",
    "        results = sp.next(results)\n",
    "        albums.extend(results['items'])\n",
    "    \n",
    "    #Here, we'll set up a set to deduplicate albums \n",
    "    seen = set() \n",
    "    \n",
    "    #sort our albums aplhabetically\n",
    "    albums.sort(key=lambda album:album['name'].lower())\n",
    "    \n",
    "    #go through every album in our sorted list\n",
    "    for album in albums:\n",
    "        \n",
    "        #if it is not in our set of albums\n",
    "        name = album['name']\n",
    "        if name not in seen:\n",
    "            \n",
    "            #add it.\n",
    "            seen.add(name)\n",
    "            \n",
    "            #now that we've added, let's set up our call for track information. Start with an empty list\n",
    "            tracks = []\n",
    "            \n",
    "            #Pass the album ID to Stopipy to grab tracks for the album. Add the object to our list\n",
    "            track_results = sp.album_tracks(album['id'])\n",
    "            tracks.extend(track_results['items'])\n",
    "            \n",
    "            #Same structure here. While there are more pages to iterate through, continue to iterate through\n",
    "            while results['next']:\n",
    "                track_results = sp.next(track_results)\n",
    "                tracks.extend(track_results['items'])\n",
    "                \n",
    "            #for all the track objects we have stored\n",
    "            for track in tracks:\n",
    "                \n",
    "                #instantiate a dictionary for each track and store relevant information\n",
    "                single_track = {}\n",
    "                single_track ['album_name'] = album['name']\n",
    "                single_track ['artist_id'] = artist_id\n",
    "                single_track ['album_id'] = album['id']               \n",
    "                single_track['track_name'] = track['name']\n",
    "                single_track['track_id'] = track['id']\n",
    "                single_track['preview_url'] = track['preview_url']\n",
    "    \n",
    "                audio_features = sp.audio_features(track['id'])\n",
    "                \n",
    "                #for audio features, there are several. Iteratively grab them.\n",
    "                for feature, value in audio_features[0].items():\n",
    "                    single_track[feature] = value\n",
    "                \n",
    "                #Append the single track to the discography list we're keeping\n",
    "                discog.append(single_track)\n",
    "\n",
    "            \n",
    "\n",
    "    #return the discography    \n",
    "    return(discog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_track_info_df =spotify_track_info_df.drop_duplicates('track_href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_track_info_df.to_csv('full_set_of_spotify_trackdata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_track_info_df = pd.merge(spotify_track_info_df,spotify_artist_df, on='artist_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_track_info_df.to_csv('full_set_of_spotify_trackdata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "final_spotify = pd.concat([spotify_track_info_df,spotify_track_info_df2]).drop_duplicates('track_href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240556, 29)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_spotify.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_spotify = pd.merge(final_spotify,spotify_artist_df, left_on='artist_id', right_on = 'artist_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_spotify.to_csv('spotify_final_230k.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owen\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (4,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "final_spotify = pd.read_csv('spotify_final_230k.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
