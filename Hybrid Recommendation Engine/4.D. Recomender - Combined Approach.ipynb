{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.D. Recommender -- Combined Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have made the following versions of recommendation systems, each with their own respective pros and cons:\n",
    "\n",
    " - **Collaborative**, using Genius.com User/Artist follower data\n",
    "  - *Pros*: Accurate and effective recommendations based on user \"behaviors.\" With music, it can be hard to determine what a user wants to listen to. But, there is latent information in follower data.\n",
    "  - *Cons*: Artist level\n",
    "  - **Novelty Level: MED**\n",
    "  \n",
    "  \n",
    " - **Item-to-Item, Album Based**, using our combined album review data\n",
    "  - *Pros*: Let professionals do the talking. These are the folks that consider themselves to be rap afficionados. The way that they dissect each album can be compared across albums to reveal similarities (i.e. politics in the case of Eminem and Dead Prez). \n",
    "  - *Cons*: Album level, the approach does not take into account the songs themselves (for example, if I want a sad song, or a loud song); Often ends up being the case that multiple albums from an established artist crowd the recs\n",
    "  - **Novelty Level: LOW**\n",
    "  \n",
    "  \n",
    "  \n",
    " - **Item-to-Item, Track Based**, using our combined lyric and audio feature data\n",
    "  - *Pros*: A very deep recommendation approach which delivers a track recommendation based on a variety of features including sentiment of lyrics, tempo, how much of a track is vocal vs instrumentals, production, etc.\n",
    "  - *Cons*: High Dimensionality can obscure some of the features. In an ideal world, we would be able to determine that User A cares more about lyrics than User B, and weight these features accordingly. In addition to this, we found this approach had extremely high novelty. This is a great option for uncovering new tracks and songs aligned to our tastes, but should not be our sole approach.\n",
    "\n",
    "  - **Novelty Level: HIGH**\n",
    "  \n",
    "In this workbook, we'll attempt to combine these approaches and get \"the best of both (or in this case three) worlds\" out of our recommender. We want to retain the novelty we are seeing with our Track based approach, while also grounding our recommendations in the artists and albums that users and critics deem similar. Workflow:\n",
    "\n",
    " 1. Build Collaborative Recommender\n",
    " 2. Build Album-Recommender\n",
    " 3. Build Track Recommender\n",
    " 4. For a given song, generate track-level recommendations\n",
    " 5. Overlay track recommendations with artists recs from collaborative filter\n",
    " 6. Overlay track recommendations with albums recs from album-to-album recommender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import lyricsgenius\n",
    "import re\n",
    "import sys\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from pyjarowinkler import distance\n",
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from gensim import corpora, models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in our user data\n",
    "users = pd.read_csv('follower_genius_500k.csv')\n",
    "users = users.drop(columns=['follower_role'])\n",
    "\n",
    "#clean up our artist_names\n",
    "users['artist_clean'] = users['artist_name'].str.replace('$', 'S')\n",
    "users['artist_clean'] = users['artist_clean'].str.replace(\"’\", \"\")\n",
    "users['artist_clean'] = users['artist_clean'].str.replace('&', 'and')\n",
    "users['artist_clean'] = users['artist_clean'].str.replace('!','') \n",
    "users['artist_clean'] = users['artist_clean'].str.replace('([ ]{2,})', ' ', regex = True) \n",
    "users['artist_clean'] = users['artist_clean'].str.strip()\n",
    "users['artist_clean'] = users['artist_clean'].str.lower()\n",
    "\n",
    "#drop missing rows\n",
    "users = users.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "#pivot out our user data\n",
    "user_pivot = users.pivot_table(index='artist_clean', columns = ['follower_name'], values = 'follow')\n",
    "\n",
    "#convert our data into a sparse matrix\n",
    "user_pivot_sparse = sparse.csr_matrix(user_pivot.fillna(0))\n",
    "\n",
    "#Use parwise distance / cosine distance on our sparse pivot; take results and push to a Datframe\n",
    "collab_recommender = pairwise_distances(user_pivot_sparse, metric='cosine')\n",
    "collab_recommender_df = pd.DataFrame(collab_recommender, columns=user_pivot.index, index=user_pivot.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1166, 150996)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_pivot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>follower_name</th>\n",
       "      <th>$hamyr</th>\n",
       "      <th>$haz</th>\n",
       "      <th>$mokeyyy</th>\n",
       "      <th>$wag Hip-Hop</th>\n",
       "      <th>,KKKKKKKLLLKK</th>\n",
       "      <th>.z3r0.</th>\n",
       "      <th>0-0-J_D_O_N-0-0</th>\n",
       "      <th>0-MXXL-0</th>\n",
       "      <th>0-Schwa-0</th>\n",
       "      <th>0-efray-0</th>\n",
       "      <th>...</th>\n",
       "      <th>‌bluii</th>\n",
       "      <th>‍   lyra messier</th>\n",
       "      <th>⁠kartashov</th>\n",
       "      <th>☀️ ✼ ☆ KayneTheDog ☆ ✼ ☀️</th>\n",
       "      <th>☣̭̰♜͙̟͇͓́ɤ͏̪̦̬̻͚̗̲Վ̘̰̥̫̜͔a̻͕͞ņ̠̟̩̼̰̲̰͞ ̖̘͇͍͎ͅ'̠̠̻̹M͚̠̣̺̬͕͞.̡̫̗O͎̠̺̪̻̺͚͟.̖̖͍̟͍̜͔M̘̖͙̝͠.̯͙͎͈̗̯͜T̺.̟̮̫̜̘͞'͕̜͢ ̛̳̫̗̬͈V͚̰̬̦༏̢̝̭̰ͅc̴̩̰̺̤̞͇͖e̹̫̮̳̥̣̘♜͙̟͇͓́☣̭̰</th>\n",
       "      <th>✞☭ Perc Nowitzki ☭✞</th>\n",
       "      <th>✰MAGZEN✰</th>\n",
       "      <th>🌴TruSwag🌴</th>\n",
       "      <th>💎 YBN Mystique 💎</th>\n",
       "      <th>🚀👑ASTROWORLD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artist_clean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>(hed) p.e.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>03 greedo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>070 shake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2 chainz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150996 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "follower_name  $hamyr  $haz  $mokeyyy  $wag Hip-Hop  ,KKKKKKKLLLKK  .z3r0.  \\\n",
       "artist_clean                                                                 \n",
       "(hed) p.e.        NaN   NaN       NaN           NaN            NaN     NaN   \n",
       "03 greedo         NaN   NaN       NaN           NaN            NaN     NaN   \n",
       "070 shake         NaN   NaN       NaN           NaN            NaN     NaN   \n",
       "100s              NaN   NaN       NaN           NaN            NaN     NaN   \n",
       "2 chainz          NaN   NaN       NaN           NaN            NaN     NaN   \n",
       "\n",
       "follower_name  0-0-J_D_O_N-0-0  0-MXXL-0  0-Schwa-0  0-efray-0  ...  ‌bluii  \\\n",
       "artist_clean                                                    ...           \n",
       "(hed) p.e.                 NaN       NaN        NaN        NaN  ...     NaN   \n",
       "03 greedo                  NaN       NaN        NaN        NaN  ...     NaN   \n",
       "070 shake                  NaN       NaN        NaN        NaN  ...     NaN   \n",
       "100s                       NaN       NaN        NaN        NaN  ...     NaN   \n",
       "2 chainz                   NaN       NaN        NaN        NaN  ...     NaN   \n",
       "\n",
       "follower_name  ‍   lyra messier  ⁠kartashov  ☀️ ✼ ☆ KayneTheDog ☆ ✼ ☀️  \\\n",
       "artist_clean                                                             \n",
       "(hed) p.e.                  NaN         NaN                        NaN   \n",
       "03 greedo                   NaN         NaN                        NaN   \n",
       "070 shake                   NaN         NaN                        NaN   \n",
       "100s                        NaN         NaN                        NaN   \n",
       "2 chainz                    NaN         NaN                        NaN   \n",
       "\n",
       "follower_name  ☣̭̰♜͙̟͇͓́ɤ͏̪̦̬̻͚̗̲Վ̘̰̥̫̜͔a̻͕͞ņ̠̟̩̼̰̲̰͞ ̖̘͇͍͎ͅ'̠̠̻̹M͚̠̣̺̬͕͞.̡̫̗O͎̠̺̪̻̺͚͟.̖̖͍̟͍̜͔M̘̖͙̝͠.̯͙͎͈̗̯͜T̺.̟̮̫̜̘͞'͕̜͢ ̛̳̫̗̬͈V͚̰̬̦༏̢̝̭̰ͅc̴̩̰̺̤̞͇͖e̹̫̮̳̥̣̘♜͙̟͇͓́☣̭̰  \\\n",
       "artist_clean                                                                                                                                                            \n",
       "(hed) p.e.                                                   NaN                                                                                                        \n",
       "03 greedo                                                    NaN                                                                                                        \n",
       "070 shake                                                    NaN                                                                                                        \n",
       "100s                                                         NaN                                                                                                        \n",
       "2 chainz                                                     NaN                                                                                                        \n",
       "\n",
       "follower_name  ✞☭ Perc Nowitzki ☭✞  ✰MAGZEN✰  🌴TruSwag🌴  💎 YBN Mystique 💎  \\\n",
       "artist_clean                                                                \n",
       "(hed) p.e.                     NaN       NaN        NaN               NaN   \n",
       "03 greedo                      NaN       NaN        NaN               NaN   \n",
       "070 shake                      NaN       NaN        NaN               NaN   \n",
       "100s                           NaN       NaN        NaN               NaN   \n",
       "2 chainz                       NaN       NaN        NaN               NaN   \n",
       "\n",
       "follower_name  🚀👑ASTROWORLD  \n",
       "artist_clean                 \n",
       "(hed) p.e.              NaN  \n",
       "03 greedo               NaN  \n",
       "070 shake               NaN  \n",
       "100s                    NaN  \n",
       "2 chainz                1.0  \n",
       "\n",
       "[5 rows x 150996 columns]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Album Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in our album data, drop nulls, reset index\n",
    "albums = pd.read_csv('./combining/albumdata/review_data_for_recommender.csv')\n",
    "albums = albums[albums.combined_reviews_clean.notnull()]\n",
    "albums = albums.reset_index()\n",
    "\n",
    "#read our TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    min_df = 2,\n",
    "    max_features = 1000,\n",
    "    ngram_range=(1, 2),\n",
    ")\n",
    "\n",
    "#build our set of Tfidf Features\n",
    "tfidf_matrix = tfidf.fit_transform(albums.combined_reviews_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7523, 1000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "\n",
    "#general cosine similarities from tfidf features\n",
    "cosine_similarities = linear_kernel(tfidf_matrix,tfidf_matrix) \n",
    "\n",
    "#ready a dict to storoue our results\n",
    "#for all entries, grab the first 100 most similar entries and store them in a list\n",
    "album_results = {}\n",
    "for idx, row in albums.iterrows():\n",
    "    similar_indices = cosine_similarities[idx].argsort()[:-200:-1] \n",
    "    similar_items = [(cosine_similarities[idx][i], albums['artist_album_clean_key'][i]) for i in similar_indices] \n",
    "    album_results[row['artist_album_clean_key']] = similar_items[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will return the track information when provided an id\n",
    "def item(id):  \n",
    "    return albums.loc[albums['artist_album_clean_key'] == id]['artist_album_clean_key']\n",
    "\n",
    "def recommend_album(item_id, num):   \n",
    "    recs = album_results[item_id][:num]   \n",
    "    return(recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in our song data\n",
    "songs = pd.read_csv('cleaned_lyrics_audio_topics.csv')\n",
    "songs.columns\n",
    "songs = songs.drop(columns=['album', 'artist','lyrics','album_id', 'album_name', 'artist_id',\n",
    "                           'duration_ms', 'id','mode', 'preview_url','time_signature',\n",
    "                           'track_href', 'track_name', 'uri','split_lyrics',\n",
    "                           'cleaned_lyrics','cleaned_lyrics_for_sentiment', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to avoid overfitting our recommender based on sentiment data. \n",
    "#Our exploration of this data has shown some potential inaccuracy. Drop the extra columns, in addition\n",
    "#to some other numerical features we don't believe are necessary\n",
    "cols_to_drop = ['track_sad_words', 'track_angry_words', 'track_joy_words', 'track_ant_words', 'track_trust_words',\n",
    "'track_fear_words', 'track_disgust_words',\n",
    "'track_surprise_words', 'track_unique_words', \n",
    "'track_total_words','artist_vocab_size','number_lines', 'tempo_x', 'valence']\n",
    "\n",
    "\n",
    "songs=songs.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'acousticness', 'danceability', 'energy', 'instrumentalness',\n",
       "       'key', 'liveness', 'loudness', 'speechiness', 'pop', 'follower',\n",
       "       'track_unique_words_pct', 'track_complexity', 'artist_vocab_complexity',\n",
       "       'track_rhyme_density', 'sentiment_track_neg', 'sentiment_track_pos',\n",
       "       'sentiment_track_neu', 'sentiment_track_comp', 'tempo_y', 'chroma_stft',\n",
       "       'spec_cent', 'spec_bw', 'rolloff', 'zcr', 'mfcc', 'hustle_pct',\n",
       "       'roots_pct', 'lust_pct', 'fun_pct', 'reflection_pct',\n",
       "       'storytelling_pct', 'drugs_pct', 'skill_pct', 'aspirational_pct',\n",
       "       'love_pct'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's see what we're working with.\n",
    "songs.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ready a unique key for our tracks\n",
    "songs['artist_album_track'] = songs['artist_clean'] +'_' + songs['album_name_clean'] +'_' + songs['track_clean']\n",
    "\n",
    "#drop non numericals\n",
    "songs_for_rec = songs.select_dtypes(exclude='object')\n",
    "\n",
    "#We're going to scale our data. do this prior to assessing similarity\n",
    "sc = StandardScaler()\n",
    "songs_for_rec_sc = sc.fit_transform(songs_for_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity \n",
    "\n",
    "#Same general approach here for tracks. However, with our hyrbid filtering approach, we\n",
    "#will take a much bigger candidate list of tracks. We'll filter on top of it.\n",
    "cosine_similarities = cosine_similarity(songs_for_rec_sc, songs_for_rec_sc) \n",
    "track_results = {}\n",
    "for idx, row in songs.iterrows():\n",
    "    similar_indices = cosine_similarities[idx].argsort()[:-1000:-1] \n",
    "    similar_items = [(cosine_similarities[idx][i], songs['artist_album_track'][i]) for i in similar_indices] \n",
    "    track_results[row['artist_album_track']] = similar_items[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-30-86c035fde309>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-30-86c035fde309>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    for rec in track_results[item_id][:num]:\u001b[0m\n\u001b[1;37m                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def item(id):  \n",
    "    return songs.loc[songs['artist_album_track'] == id]['artist_album_track'] \n",
    "def recommend_track(item_id, num):   \n",
    "    for rec in track_results[item_id][:num]: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating Track Recommender -- Kendrick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our output for Kendrick Lamar. We'll begin by building our candidate track list from our track features. We'll then read in our results from our album review recommender and our collaborative filter. We'll flag where we see overlap and sort accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_album_track = 'kendrick lamar_to pimp a butterfly_alright'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build empty lists to store results\n",
    "rec_arts =[]\n",
    "rec_albs = []\n",
    "rec_songs = []\n",
    "\n",
    "#grab our results for our track\n",
    "for rec in track_results[artist_album_track]:\n",
    "    \n",
    "    #split and store our general information\n",
    "    artist=rec[1].split(\"_\")[0]\n",
    "    album=rec[1].split(\"_\")[1]\n",
    "    track=rec[1].split(\"_\")[2]\n",
    "    rec_arts.append(artist)\n",
    "    rec_albs.append(album)\n",
    "    rec_songs.append(track)\n",
    "\n",
    "#build a dataframe from the results\n",
    "temp_track_results = pd.DataFrame(zip(rec_arts,rec_albs,rec_songs)).rename(columns={0: \"artist\", 1: \"album\", 2: \"track\"})\n",
    "\n",
    "#Try grabbing a list of the top 10 related artists. It may be that we don't have an exact string match, so \n",
    "#list will be empty if this is the case. We'll then flag if we found that artist\n",
    "try:\n",
    "    top_related_artists = list(collab_recommender_df[artist].sort_values(ascending=True)[:20].index)\n",
    "except:\n",
    "    top_related_artists = []\n",
    "    \n",
    "temp_track_results['artist_based_rec'] = 0\n",
    "temp_track_results.loc[temp_track_results.artist.isin(top_related_artists),'artist_based_rec'] = 1\n",
    "\n",
    "album_based_album_recs = []\n",
    "album_based_artist_recs = []\n",
    "\n",
    "#Try grabbing a list of the top related albums. It may be that we don't have an exact string match, so \n",
    "#list will be empty if this is the case. We'll then flag if we found that artist\n",
    "try:\n",
    "    for entry in recommend_album(artist + '|' + album,200):\n",
    "        album_based_artist_recs.append(entry[1].split('|')[0])\n",
    "        album_based_album_recs.append(entry[1].split('|')[1])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#Overlay our results in the dataframe\n",
    "temp_track_results['album_based_artist_rec'] = 0\n",
    "temp_track_results['album_based_album_rec'] = 0\n",
    "temp_track_results.loc[temp_track_results.artist.isin(album_based_artist_recs),'album_based_artist_rec'] = 1\n",
    "temp_track_results.loc[temp_track_results.album.isin(album_based_album_recs),'album_based_album_rec'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>track</th>\n",
       "      <th>artist_based_rec</th>\n",
       "      <th>album_based_artist_rec</th>\n",
       "      <th>album_based_album_rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>sheck wes</td>\n",
       "      <td>mudboy</td>\n",
       "      <td>kyrie</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>lil pump</td>\n",
       "      <td>lil pump</td>\n",
       "      <td>back</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>smokepurpp</td>\n",
       "      <td>deadstar</td>\n",
       "      <td>nose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>megan thee stallion</td>\n",
       "      <td>tina snow</td>\n",
       "      <td>cocky af</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>lil keed</td>\n",
       "      <td>keed talk to em</td>\n",
       "      <td>red hot</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>rico nasty</td>\n",
       "      <td>sugar trap 2</td>\n",
       "      <td>phone</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>megan thee stallion</td>\n",
       "      <td>tina snow</td>\n",
       "      <td>cognac queen</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>danny brown</td>\n",
       "      <td>xxx</td>\n",
       "      <td>i will</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>megan thee stallion</td>\n",
       "      <td>make it hot</td>\n",
       "      <td>geekin</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>comethazine</td>\n",
       "      <td>bawskee</td>\n",
       "      <td>sticks out the window</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>yg</td>\n",
       "      <td>just red up 2</td>\n",
       "      <td>this yick</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>megan thee stallion</td>\n",
       "      <td>make it hot</td>\n",
       "      <td>naturally</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>21 savage</td>\n",
       "      <td>the slaughter tape</td>\n",
       "      <td>drip</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>smokepurpp</td>\n",
       "      <td>deadstar</td>\n",
       "      <td>fingers blue</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>trippie redd</td>\n",
       "      <td>a love letter to you 3</td>\n",
       "      <td>1400 999 freestyle</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>gunna</td>\n",
       "      <td>drip or drown 2</td>\n",
       "      <td>on a mountain</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>yg</td>\n",
       "      <td>stay dangerous</td>\n",
       "      <td>too cocky</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>skepta</td>\n",
       "      <td>konnichiwa</td>\n",
       "      <td>ladies hit squad</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>comethazine</td>\n",
       "      <td>bawskee 3.5</td>\n",
       "      <td>just saying</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>azealia banks</td>\n",
       "      <td>broke with expensive taste</td>\n",
       "      <td>wallace</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist                       album                  track  \\\n",
       "7              sheck wes                      mudboy                  kyrie   \n",
       "10              lil pump                    lil pump                   back   \n",
       "24            smokepurpp                    deadstar                   nose   \n",
       "29   megan thee stallion                   tina snow               cocky af   \n",
       "34              lil keed             keed talk to em                red hot   \n",
       "36            rico nasty                sugar trap 2                  phone   \n",
       "38   megan thee stallion                   tina snow           cognac queen   \n",
       "39           danny brown                         xxx                 i will   \n",
       "46   megan thee stallion                 make it hot                 geekin   \n",
       "47           comethazine                     bawskee  sticks out the window   \n",
       "57                    yg               just red up 2              this yick   \n",
       "58   megan thee stallion                 make it hot              naturally   \n",
       "66             21 savage          the slaughter tape                   drip   \n",
       "79            smokepurpp                    deadstar           fingers blue   \n",
       "90          trippie redd      a love letter to you 3     1400 999 freestyle   \n",
       "94                 gunna             drip or drown 2          on a mountain   \n",
       "97                    yg              stay dangerous              too cocky   \n",
       "100               skepta                  konnichiwa       ladies hit squad   \n",
       "103          comethazine                 bawskee 3.5            just saying   \n",
       "107        azealia banks  broke with expensive taste                wallace   \n",
       "\n",
       "     artist_based_rec  album_based_artist_rec  album_based_album_rec  \n",
       "7                   1                       0                      0  \n",
       "10                  0                       1                      0  \n",
       "24                  1                       1                      1  \n",
       "29                  0                       1                      0  \n",
       "34                  1                       0                      0  \n",
       "36                  0                       1                      0  \n",
       "38                  0                       1                      0  \n",
       "39                  0                       1                      0  \n",
       "46                  0                       1                      0  \n",
       "47                  1                       0                      0  \n",
       "57                  0                       1                      0  \n",
       "58                  0                       1                      0  \n",
       "66                  1                       1                      0  \n",
       "79                  1                       1                      1  \n",
       "90                  1                       1                      0  \n",
       "94                  1                       0                      0  \n",
       "97                  0                       1                      1  \n",
       "100                 0                       1                      1  \n",
       "103                 1                       0                      0  \n",
       "107                 0                       1                      1  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See the results\n",
    "temp_track_results[(temp_track_results['artist_based_rec'] == 1) | (temp_track_results['album_based_artist_rec'] == 1) | (temp_track_results['album_based_album_rec'] == 1)].drop_duplicates().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're still dealing with a LOT of repetition at the artist level. We're going to balance our output across recommenders to avoid this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Recommender and Build Random Tester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're going to do two things:\n",
    " - There are pros and cons to our output across recommender. We'll ensure that 50% of our recs are coming from a collaborative filter, and that none of the artists here are being repeated. Next, we'll grab 30% of our tracks from our album review data, and ensure that no duplication is occuring here. Finally, we'll slow in the remaining 20% with the most similar tracks based on lyrical and audio data which shows the greatest promise for novelty.\n",
    " \n",
    " - We'll build a function to randomly select a track and generate a test for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_track():\n",
    "    #We're going to randomly grab a track this time, so we can iterate and check the results. \n",
    "    #this will inform our presentation\n",
    "    random_song = np.random.choice(list(songs['artist_album_track'].values))\n",
    "    random_track_id = songs[songs.artist_album_track == random_song]['track_id']\n",
    "\n",
    "    song = random_song.split('_')[2]\n",
    "    artist = random_song.split('_')[0]\n",
    "    album = random_song.split('_')[1]\n",
    "    track_id= random_track_id\n",
    "    artist_album_track = artist + '_' + album + '_' + song\n",
    "    return(artist_album_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15803    MARY JANE\n",
       "Name: song, dtype: object"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs[songs.artist_album_track == artist_album_track]['artist_clean'].str.upper()\n",
    "songs[songs.artist_album_track == artist_album_track]['album_name_clean'].str.upper()\n",
    "songs[songs.artist_album_track == artist_album_track]['song'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recs():\n",
    "    \n",
    "    #build empty lists to store results\n",
    "    rec_arts =[]\n",
    "    rec_albs = []\n",
    "    rec_songs = []\n",
    "\n",
    "    #grab our current track info\n",
    "    artist_album_track = current_track()\n",
    "    artist_name_for_print = songs[songs.artist_album_track == artist_album_track]['artist_clean'].str.upper().head(1).values\n",
    "    album_name_for_print = songs[songs.artist_album_track == artist_album_track]['album_name_clean'].str.upper().head(1).values\n",
    "    track_name_for_print = songs[songs.artist_album_track == artist_album_track]['song'].str.upper().head(1).values\n",
    "    \n",
    "    #howdy user\n",
    "    print('Hello! You are currently listening to...')\n",
    "    print('')\n",
    "    print(f'ARTIST: {artist_name_for_print}')\n",
    "    print(f'ALBUM: {album_name_for_print}')\n",
    "    print(f'TRACK: {track_name_for_print}')\n",
    "    print('')\n",
    "    print('We recommend checking out...')\n",
    "\n",
    "    \n",
    "    #grab our results for our track\n",
    "    for rec in track_results[artist_album_track]:\n",
    "\n",
    "        #split and store our general information\n",
    "        artist=rec[1].split(\"_\")[0]\n",
    "        album=rec[1].split(\"_\")[1]\n",
    "        track=rec[1].split(\"_\")[2]\n",
    "        rec_arts.append(artist)\n",
    "        rec_albs.append(album)\n",
    "        rec_songs.append(track)\n",
    "\n",
    "    #build a dataframe from the results\n",
    "    temp_track_results = pd.DataFrame(zip(rec_arts,rec_albs,rec_songs)).rename(columns={0: \"artist\", 1: \"album\", 2: \"track\"})\n",
    "\n",
    "    #Try grabbing a list of the top 10 related artists. It may be that we don't have an exact string match, so \n",
    "    #list will be empty if this is the case. We'll then flag if we found that artist\n",
    "    try:\n",
    "        top_related_artists = list(collab_recommender_df[artist].sort_values(ascending=True)[:20].index)\n",
    "    except:\n",
    "        top_related_artists = []\n",
    "\n",
    "    temp_track_results['artist_based_rec'] = 0\n",
    "    temp_track_results.loc[temp_track_results.artist.isin(top_related_artists),'artist_based_rec'] = 1\n",
    "\n",
    "    album_based_album_recs = []\n",
    "    album_based_artist_recs = []\n",
    "\n",
    "    #Try grabbing a list of the toprelated albums. It may be that we don't have an exact string match, so \n",
    "    #list will be empty if this is the case. We'll then flag if we found that artist\n",
    "    try:\n",
    "        for entry in recommend_album(artist + '|' + album,200):\n",
    "            album_based_artist_recs.append(entry[1].split('|')[0])\n",
    "            album_based_album_recs.append(entry[1].split('|')[1])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #Overlay our results in the dataframe\n",
    "    temp_track_results['album_based_artist_rec'] = 0\n",
    "    temp_track_results['album_based_album_rec'] = 0\n",
    "    temp_track_results.loc[temp_track_results.artist.isin(album_based_artist_recs),'album_based_artist_rec'] = 1\n",
    "    temp_track_results.loc[temp_track_results.album.isin(album_based_album_recs),'album_based_album_rec'] = 1\n",
    "\n",
    "    #Our final recs will be combined here\n",
    "    final_recs = {'artist':[], 'album':[], 'track':[], 'artist_based_rec':[], 'album_based_artist_rec':[], 'album_based_album_rec':[]} \n",
    "    final_recs = pd.DataFrame(final_recs)\n",
    "    \n",
    "    #grab a variety of tracks from our recommenders and deduplicate at the artist level to increase diversity\n",
    "    final_recs = final_recs.append(temp_track_results[(temp_track_results['artist_based_rec'] == 1)].drop_duplicates(subset='artist').head(5))\n",
    "    final_recs = final_recs.append(temp_track_results[(temp_track_results['album_based_artist_rec'] == 1)].drop_duplicates(subset='artist').head(3))\n",
    "    final_recs = final_recs.append(temp_track_results.drop_duplicates(subset='artist').head(20))\n",
    "\n",
    "    final_recs = final_recs.drop_duplicates().head(10).sample(frac=1).reset_index(drop=True).drop(columns=['album_based_album_rec'])\n",
    "    final_recs['combined_flag'] = final_recs['album_based_artist_rec'] + final_recs['artist_based_rec']\n",
    "    final_recs = final_recs.sort_values(by='artist_based_rec', ascending=False).sort_values(by='combined_flag', ascending=False).drop(columns=['combined_flag'])\n",
    "    final_recs.columns = ['artist', 'album', 'track', 'follower flag', 'review flag']\n",
    "    final_recs = final_recs.apply(lambda x: x.astype(str).str.upper())\n",
    "    final_recs = final_recs.apply(lambda x: x.astype(str).str.upper())\n",
    "    \n",
    "    display(final_recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rec Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! You are currently listening to...\n",
      "\n",
      "ARTIST: ['KUTT CALHOUN']\n",
      "ALBUM: ['FEATURE PRESENTATION']\n",
      "TRACK: ['COLORS']\n",
      "\n",
      "We recommend checking out...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>track</th>\n",
       "      <th>follower flag</th>\n",
       "      <th>review flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SWINGS</td>\n",
       "      <td>#1 MIXTAPE, VOL. 2</td>\n",
       "      <td>NO MERCY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CRUCIAL STAR</td>\n",
       "      <td>MAZE GARDEN</td>\n",
       "      <td>SINGER SONGWRITER</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>THE QUIETT</td>\n",
       "      <td>MILLIONAIRE POETRY</td>\n",
       "      <td>PRIME TIME</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>BEWHY</td>\n",
       "      <td>THE BLIND STAR</td>\n",
       "      <td>WRIGHT BROTHERS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TRAGEDY KHADAFI</td>\n",
       "      <td>THUG MATRIX II</td>\n",
       "      <td>WHATS POPPIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ANT BANKS</td>\n",
       "      <td>DO OR DIE</td>\n",
       "      <td>BAY AREA MASSACRE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BIG MELLO</td>\n",
       "      <td>THE GIFT</td>\n",
       "      <td>KMJ KILLAS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>INDO G</td>\n",
       "      <td>ANGEL DUST</td>\n",
       "      <td>AINT NO BITCH IN MY BLOOD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>QWEL</td>\n",
       "      <td>SO BE IT</td>\n",
       "      <td>WHITE ELEPHANT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>MR. CAPONE-E</td>\n",
       "      <td>LOVE JAMS</td>\n",
       "      <td>STILL MISSING YOU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist               album                      track  \\\n",
       "2           SWINGS  #1 MIXTAPE, VOL. 2                   NO MERCY   \n",
       "3     CRUCIAL STAR         MAZE GARDEN          SINGER SONGWRITER   \n",
       "5       THE QUIETT  MILLIONAIRE POETRY                 PRIME TIME   \n",
       "7            BEWHY      THE BLIND STAR            WRIGHT BROTHERS   \n",
       "0  TRAGEDY KHADAFI      THUG MATRIX II               WHATS POPPIN   \n",
       "1        ANT BANKS           DO OR DIE          BAY AREA MASSACRE   \n",
       "4        BIG MELLO            THE GIFT                 KMJ KILLAS   \n",
       "6           INDO G          ANGEL DUST  AINT NO BITCH IN MY BLOOD   \n",
       "8             QWEL            SO BE IT             WHITE ELEPHANT   \n",
       "9     MR. CAPONE-E           LOVE JAMS          STILL MISSING YOU   \n",
       "\n",
       "  follower flag review flag  \n",
       "2           1.0         0.0  \n",
       "3           1.0         0.0  \n",
       "5           1.0         0.0  \n",
       "7           1.0         0.0  \n",
       "0           0.0         0.0  \n",
       "1           0.0         0.0  \n",
       "4           0.0         0.0  \n",
       "6           0.0         0.0  \n",
       "8           0.0         0.0  \n",
       "9           0.0         0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "generate_recs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
