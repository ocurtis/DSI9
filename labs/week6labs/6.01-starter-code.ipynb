{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.01 - Supervised Learning Model Comparison\n",
    "\n",
    "Recall the \"data science process.\"\n",
    "\n",
    "1. Define the problem.\n",
    "2. Gather the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus mostly on creating (and then comparing) many regression and classification models. Thus, we'll define the problem and gather the data for you.\n",
    "Most of the questions requiring a written response can be written in 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the problem.\n",
    "\n",
    "You are a data scientist with a financial services company. Specifically, you want to leverage data in order to identify potential customers.\n",
    "\n",
    "If you are unfamiliar with \"401(k)s\" or \"IRAs,\" these are two types of retirement accounts. Very broadly speaking:\n",
    "- You can put money for retirement into both of these accounts.\n",
    "- The money in these accounts gets invested and hopefully has a lot more money in it when you retire.\n",
    "- These are a little different from regular bank accounts in that there are certain tax benefits to these accounts. Also, employers frequently match money that you put into a 401k.\n",
    "- If you want to learn more about them, check out [this site](https://www.nerdwallet.com/article/ira-vs-401k-retirement-accounts).\n",
    "\n",
    "We will tackle one regression problem and one classification problem today.\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k.\n",
    "\n",
    "Check out the data dictionary [here](http://fmwww.bc.edu/ec-p/data/wooldridge2k/401KSUBS.DES).\n",
    "\n",
    "### NOTE: When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable. When predicting `e401k`, you may use the entire dataframe if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Gather the data.\n",
    "\n",
    "##### 1. Read in the data from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor, AdaBoostRegressor, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "#Import model validation and preprocessing packages\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, PowerTransformer\n",
    "#Import regression, metric, and regularization packages\n",
    "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, RidgeCV, LassoCV, ElasticNetCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('401ksubs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61.23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e401k    inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0      0  13.17     0     0   40      1    4.575      0     1   173.4489   \n",
       "1      1  61.23     0     1   35      1  154.000      1     0  3749.1130   \n",
       "\n",
       "   agesq  \n",
       "0   1600  \n",
       "1   1225  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What are 2-3 other variables that, if available, would be helpful to have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Home Location; Occupation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Suppose a peer recommended putting `race` into your model in order to better predict who to target when advertising IRAs and 401(k)s. Why would this be an unethical decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Because the model can be used to discriminate based on this variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the data.\n",
    "\n",
    "##### 4. When attempting to predict income, which feature(s) would we reasonably not use? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e401k     0\n",
       "inc       0\n",
       "marr      0\n",
       "male      0\n",
       "age       0\n",
       "fsize     0\n",
       "nettfa    0\n",
       "p401k     0\n",
       "pira      0\n",
       "incsq     0\n",
       "agesq     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e401k       int64\n",
       "inc       float64\n",
       "marr        int64\n",
       "male        int64\n",
       "age         int64\n",
       "fsize       int64\n",
       "nettfa    float64\n",
       "p401k       int64\n",
       "pira        int64\n",
       "incsq     float64\n",
       "agesq       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.corr());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inc       1.000000\n",
       "incsq     0.940161\n",
       "nettfa    0.376586\n",
       "pira      0.364354\n",
       "marr      0.362008\n",
       "p401k     0.270833\n",
       "e401k     0.268178\n",
       "fsize     0.110170\n",
       "age       0.105638\n",
       "agesq     0.087305\n",
       "male     -0.069871\n",
       "Name: inc, dtype: float64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['inc'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e401k       0.0000\n",
       "inc        10.0080\n",
       "marr        0.0000\n",
       "male        0.0000\n",
       "age        25.0000\n",
       "fsize       1.0000\n",
       "nettfa   -502.3020\n",
       "p401k       0.0000\n",
       "pira        0.0000\n",
       "incsq     100.1601\n",
       "agesq     625.0000\n",
       "Name: min, dtype: float64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T['min']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the following order of strong income prediction:** Net Financial Asasets (nettfa), Marital Status (marr), Family Size(fsize), Age (age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What two variables have already been created for us through feature engineering? Come up with a hypothesis as to why subject-matter experts may have done this.\n",
    "> This need not be a \"statistical hypothesis.\" Just brainstorm why SMEs might have done this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The squared terms were likely created through polynomial feature engineering in an attempt to increase the predictive quality of their models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "##### 6. Looking at the data dictionary, one variable description appears to be an error. What is this error, and what do you think the correct value would be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Both age and income have descriptions of squared features which we suspect not to be the case. These features should simply be age and income, without the square."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 1: Regression Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: What features best predict one's income?\n",
    "- When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable.\n",
    "\n",
    "##### 7. List all modeling tactics we've learned that could be used to solve a regression problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific regression problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple linear regression model, lasso, ridge, elasticnet, k-nearest neighbors model, decision tree, random forest, Kneighbors regressor, Adaboost, SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['inc'].plot(kind='hist');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Regardless of your answer to number 7, fit at least one of each of the following models to attempt to solve the regression problem above:\n",
    "    - a multiple linear regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    - a support vector regressor\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend setting a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['inc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['nettfa', 'marr', 'fsize', 'age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_models = {\n",
    "    'Lin': LinearRegression(),\n",
    "    'KNR': KNeighborsRegressor(),\n",
    "    'DTR': DecisionTreeRegressor(),\n",
    "    'Bag': BaggingRegressor(random_state=42),\n",
    "    'Ada': AdaBoostRegressor(random_state=42),\n",
    "    'SVR': SVR(),  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nettfa    9.561055\n",
       "fsize     0.728968\n",
       "age       0.397852\n",
       "marr     -0.515991\n",
       "dtype: float64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.skew().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer()\n",
    "pt.fit(X_train)\n",
    "X_train_pt = pt.transform(X_train)\n",
    "X_test_pt = pt.transform(X_test)\n",
    "\n",
    "pt_y = PowerTransformer()\n",
    "pt_y.fit(y_train.to_frame())\n",
    "y_train_pt = pt_y.transform(y_train.to_frame())\n",
    "y_test_pt = pt_y.transform(y_test.to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(X_train_pt)\n",
    "X_train_pt_ss = ss.transform(X_train_pt)\n",
    "X_test_pt_ss = ss.transform(X_test_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score_regressor_model(model,train_data,train_values):\n",
    "\n",
    "    train_cv_results = cross_val_score(model, train_data, train_values, cv=3).mean()\n",
    "    \n",
    "    model.fit(train_data, train_values)\n",
    "    \n",
    "    test_results = model.score(X_test_pt_ss,y_test_pt)\n",
    "    \n",
    "    return (train_cv_results, test_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owen\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28375125455846434"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = KNeighborsRegressor()\n",
    "lr.fit(X_train_pt_ss, y_train_pt)\n",
    "cross_val_score(lr,X_train_pt_ss, y_train_pt).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lin\n",
      "Train Score: 0.24167279613717563\n",
      "Test Score: 0.2123522586861959\n",
      "\n",
      "RMSE Train: 0.8665852229660725\n",
      "RMSE Test: 0.8846982795821662\n",
      "\n",
      "KNR\n",
      "Train Score: 0.2765830988320596\n",
      "Test Score: 0.30461280491320153\n",
      "\n",
      "RMSE Train: 0.6866175399796198\n",
      "RMSE Test: 0.8191234616460145\n",
      "\n",
      "DTR\n",
      "Train Score: -0.20128605114235554\n",
      "Test Score: -0.14646925875959646\n",
      "\n",
      "RMSE Train: 0.14391762579234144\n",
      "RMSE Test: 1.084543497604798\n",
      "\n",
      "Bag\n",
      "Train Score: 0.25536720714060357\n",
      "Test Score: 0.2890084373188867\n",
      "\n",
      "RMSE Train: 0.37663313594740255\n",
      "RMSE Test: 0.8486622924750093\n",
      "\n",
      "Ada\n",
      "Train Score: 0.3653720811575346\n",
      "Test Score: 0.375741710295494\n",
      "\n",
      "RMSE Train: 0.7879892575694732\n",
      "RMSE Test: 0.7958752636826145\n",
      "\n",
      "SVR\n",
      "Train Score: 0.2099113598690679\n",
      "Test Score: 0.15202162721092805\n",
      "\n",
      "RMSE Train: 0.8860005800509401\n",
      "RMSE Test: 0.907904892001006\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "   \n",
    "    # ignore all caught warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    for key in regression_models.keys():\n",
    "        print()\n",
    "        print(key)\n",
    "        model = regression_models[key]\n",
    "        model.fit(X_train_pt_ss, y_train_pt)\n",
    "        print(f\"Train Score: {cross_val_score(model, X_train_pt_ss, y_train_pt, cv = 5).mean()}\")\n",
    "        print(f\"Test Score: {cross_val_score(model, X_test_pt_ss, y_test_pt, cv = 5).mean()}\")\n",
    "        print()\n",
    "        train_preds = model.predict(X_train_pt_ss)\n",
    "        test_preds = model.predict(X_test_pt_ss)\n",
    "        print(f\"RMSE Train: {mean_squared_error(y_train_pt, train_preds) **.5}\")\n",
    "        print(f\"RMSE Test: {mean_squared_error(y_test_pt, test_preds) **.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24321069,  0.47345165, -0.12772459,  0.05006565]])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_pt_ss, y_train_pt)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['nettfa', 'marr', 'fsize', 'age'], dtype='object')"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. What is bootstrapping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Bootstrapping is the concept of resampling data with replacement. For each sample you take the same number of observations and compare the results. You maintain the same number (n) in order to fit your estimators on the same amount of data (prevents us from introducing another variable). Bagging is \"bootstrap aggregation\" -- it's a method in which models are trained on bootstrapped samples (each with their own particular model fit), aggregated, and scored. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. What is the difference between a decision tree and a set of bagged decision trees? Be specific and precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A set of bagged decision trees is an ensemble modeling approach based on the principles of boostrapping and aggregation (aka bagging). This set of trees is set on randomized samples from the same training data, at which point results are aggregated and the model is assessed. This is helpful for a model like a DecisionTree-- this model in particular can overfit quickly on training data (particularly if hyperparamters like max depth are not specified)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. What is the difference between a set of bagged decision trees and a random forest? Be specific and precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The difference here is that a RandomForest model varies the set of features that each estimator within the ensemble model is trained on. In addition to varying the observations (as seen with bagging), the features are also varied. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Why might a random forest be superior to a set of bagged decision trees?\n",
    "> Hint: Consider the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It introduces more variety into the model fitting process, which in turn results in more randomness and will then generalize better beyond the test set (driving down variance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 1: Regression Problem)\n",
    "\n",
    "##### 13. Using RMSE, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "See #8 Above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Based on training RMSE and testing RMSE, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "DecisionTreeRegressor appears to be very bad -- the R2 score here is negative. Beyond this model, we are seeing pretty varied results between R2 and RMSE. Some of the models that are popping from an overfitting standpoint are our BaggingClassifier and KNR models. While majority of models are showing a small gap between training and test in terms of RMSE, these two in particular are showing sigificant gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I'm going to use LinearRegression here as the goal was the understand what features are most important. Based on this objective, I want to preserve interpretability as much as possible for internal stakeholders involved in this proccess. In addition to this, the RMSE is relatively close to some of our more advanced models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I would test ElasticNet, Ridge, and Lasso Regression here. I would also consider testing polynomial features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 2: Classification Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: Predict whether or not one is eligible for a 401k.\n",
    "- When predicting `e401k`, you may use the entire dataframe if you wish.\n",
    "\n",
    "##### 17. While you're allowed to use every variable in your dataframe, mention at least one disadvantage of using `p401k` in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "p401k stands for 'participation in 401k.' We are estimating e401k which determines eligibility for 401k. The goal here is to identify potential customers. As this variable will be a strong predictor of eligiblity, it will be a significant component of our model. If we employ our model, we'll then be optimizing toward people that already have 401ks. While we might be able to lure them away from their current plans, the acqusition costs will be significant relative to customers without a 401k that satisfy our other criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. List all modeling tactics we've learned that could be used to solve a classification problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific classification problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "logistic regression, naive bayes, KNeighbors, RandomForest, SVM, Adaboost, DecisionTrees, Bagged Trees, Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. Regardless of your answer to number 18, fit at least one of each of the following models to attempt to solve the classification problem above:\n",
    "    - a logistic regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    - a support vector classifier\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend using a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class = df.drop(columns=['e401k', 'p401k'])\n",
    "y_class = df['e401k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_class,y_class,random_state=42, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Log': LogisticRegression(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Dec': DecisionTreeClassifier(random_state=42),\n",
    "    'Ran': RandomForestClassifier(random_state=42),\n",
    "    'Ada': AdaBoostClassifier(random_state=42),\n",
    "    'SVC': SVC(random_state=42),  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score_model(model,train_data,train_values):\n",
    "\n",
    "    train_cv_results = cross_val_score(model, train_data, train_values, cv=3).mean()\n",
    "    \n",
    "    model.fit(train_data, train_values)\n",
    "    \n",
    "    test_results = model.score(X_test,y_test)\n",
    "    \n",
    "    return (train_cv_results, test_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log's Train Score: 0.65, Test Score: 0.65, Differennce: 0.01.\n",
      "\n",
      "KNN's Train Score: 0.6, Test Score: 0.62, Differennce: 0.02.\n",
      "\n",
      "Dec's Train Score: 0.6, Test Score: 0.59, Differennce: 0.01.\n",
      "\n",
      "Ran's Train Score: 0.65, Test Score: 0.65, Differennce: 0.0.\n",
      "\n",
      "Ada's Train Score: 0.68, Test Score: 0.68, Differennce: 0.01.\n",
      "\n",
      "SVC's Train Score: 0.6, Test Score: 0.61, Differennce: 0.01.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prevent warnings from flooding the screen\n",
    "with warnings.catch_warnings():\n",
    "   \n",
    "    # ignore all caught warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    for key in models.keys():\n",
    "        train_results, test_results = fit_score_model(models[key],X_train,y_train)\n",
    "        print(f\"{key}'s Train Score: {round(train_results,2)}, Test Score: {round(test_results,2)}, Differennce: {round(np.abs(train_results -test_results),2)}.\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 2: Classfication Problem)\n",
    "\n",
    "##### 20. Suppose our \"positive\" class is that someone is eligible for a 401(k). What are our false positives? What are our false negatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.607871\n",
       "1    0.392129\n",
       "Name: e401k, dtype: float64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_class.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(random_state=42)\n",
    "ada.fit(X_train,y_train)\n",
    "preds=ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n"
     ]
    }
   ],
   "source": [
    "print(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 392 false positives in this workflow. **This represent the number of users that we predicted to not be eligible for a 401k but in fact were eligble for a 401k.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. In this specific case, would we rather minimize false positives or minimize false negatives? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The positive class in this classification problem is \"users not eligible for a 401k\"....\n",
    "\n",
    "A **False Positive** is: A user that our model classified as not being eligible for a 401k but in fact is.\n",
    "A **False Negative** is: A user that our model classified as being eligible for a 401k but in fact is not.\n",
    "\n",
    "In this case, I would be more interested in minimizing false negatives. We'd effectively be spending money against users that will not be able to open a product that we are advertising to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 22. Suppose we wanted to optimize for the answer you provided in problem 21. Which metric would we optimize in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here we'd want to look at Specifiity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 23. Suppose that instead of optimizing for the metric in problem 21, we wanted to balance our false positives and false negatives using `f1-score`. Why might [f1-score](https://en.wikipedia.org/wiki/F1_score) be an appropriate metric to use here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "F1 Score is a metric you want to use when you are balancing Precision with Recall. In this case, we would be minimiing both the spend against ineligble targets, and improving our ability to identify eligible targets that we were not previously surfacing through our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 24. Using f1-score, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log\n",
      "0.4686436558094312\n",
      "0.46394351991931415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owen\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "0.6395759717314489\n",
      "0.47005029721079106\n",
      "Dec\n",
      "1.0\n",
      "0.4813895781637717\n",
      "Ran\n",
      "0.9649122807017544\n",
      "0.4885496183206106\n",
      "Ada\n",
      "0.5777479892761394\n",
      "0.5508982035928144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owen\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "0.9955028618152085\n",
      "0.011522633744855966\n"
     ]
    }
   ],
   "source": [
    "    for key in models.keys():\n",
    "        model = models[key]\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict(X_train)\n",
    "        print(key) \n",
    "        print(f1_score(pred_train,y_train))\n",
    "        \n",
    "        pred_test = model.predict(X_test)\n",
    "        print(f1_score(pred_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25. Based on training f1-score and testing f1-score, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "KNN, Decision Tree, SVC are all severely overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Adaboost appears to  be a strong contender. It's showing stability across training and test data sets. While it's slightly overfit, parameter tuning may enable us to reduce this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 27. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I would gridsearch n_estimators and learning rate to hypertune. I would also consider plugging AdaBoost in with another series of models as part of a larger voting classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Answer the problem.\n",
    "\n",
    "##### BONUS: Briefly summarize your answers to the regression and classification problems. Be sure to include any limitations or hesitations in your answer.\n",
    "\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
