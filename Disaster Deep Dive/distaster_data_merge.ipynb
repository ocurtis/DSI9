{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaster Data Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll be reading in our **cleaned fema dataset** and combining this with some additional information based on FEMA's **distaster code dataset**. This additional dataset gives us purview into the type of distaster, among other relevant features that will be important to our end product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read In Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by reading in our data and taking a look at the columns for our *new* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate and store data.\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owen\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Read in files from .csvs\n",
    "clean_df = pd.read_csv('./data/fema_clean.csv')\n",
    "codes_df = pd.read_csv('./data/disaster_code_api.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['declarationDate', 'declaredCountyArea', 'disasterCloseOutDate',\n",
       "       'disasterNumber', 'disasterType', 'fyDeclared', 'hash',\n",
       "       'hmProgramDeclared', 'iaProgramDeclared', 'id', 'ihProgramDeclared',\n",
       "       'incidentBeginDate', 'incidentEndDate', 'incidentType', 'lastRefresh',\n",
       "       'paProgramDeclared', 'placeCode', 'state', 'title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take a look at the columns we generated\n",
    "codes_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Columns Prior to Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be consistent with our column naming convention (snake case). Let's take some steps to clean up our column names before proceeding any further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disaster code column name clean\n",
    "codes_df.columns = map(str.lower, codes_df.columns)\n",
    "codes_df.columns = codes_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a significant amount of information to sift through in this dataset. For our purposes, we're really only convered with *5* columns. We'll now drop all irrelevant columns and remove duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disaster code df feature reduction and drop duplicate entries for disasters\n",
    "codes_df = codes_df[['disasternumber','disastertype', 'incidenttype', 'incidentbegindate', 'incidentenddate']]\n",
    "codes_df = codes_df.drop_duplicates('disasternumber')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can merge our disparate dataframes on *disaster_number.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join em\n",
    "combined_df = pd.merge(clean_df, codes_df, left_on='disaster_number', right_on='disasternumber', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shapes of our dataframes for consistency, in addition to the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90579, 23), (3932, 5))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape, codes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90579, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['disaster_number', 'state', 'county', 'city', 'zipCode', 'valid_registration', 'avg_damage', 'tot_inspected', 'tot_damage', 'no_damage', 'inspect_1_10000', 'inspect_10001_20000', 'inspect_20001_30000', 'inspect_greater_30000', 'approve_assistance', 'tot_approve_ihp_amt', 'repair_replace_amt', 'rental_amt', 'other_needs_amt', 'approve_1_10000', 'approve_10001_25000', 'approve_25001_max', 'tot_max_grants', 'disasternumber', 'disastertype', 'incidenttype', 'incidentbegindate', 'incidentenddate'], dtype='object')"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read to .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good to go! Read this to .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('combined.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
